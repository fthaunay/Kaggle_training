{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import time\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_missing(df):\n",
    "    df[\"category_name\"] = df.loc[:,\"category_name\"].replace(np.NaN, \"\")\n",
    "    df[\"brand_name\"] = df.loc[:,\"brand_name\"].replace(np.NaN, \"\")\n",
    "    df[\"item_description\"] = df.loc[:,\"item_description\"].replace(np.NaN, \"\")\n",
    "    return df\n",
    "\n",
    "def split_cat(text):\n",
    "    if text.count('/') > 1:\n",
    "        return text.split(\"/\")\n",
    "    else:\n",
    "        return ([\"No Label\", \"No Label\", \"No Label\"])\n",
    "\n",
    "def transform_category_name(df):\n",
    "    df.loc[:,'general_cat'], df.loc[:,'subcat_1'], df.loc[:,'subcat_2'] = \\\n",
    "    zip(*df['category_name'].apply(lambda x: split_cat(x)))\n",
    "    return df\n",
    "\n",
    "def stem_tokenize(text, stop_words=[]):\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = regexp_tokenize(text, pattern=r\"[A-Za-z]\\w+\")\n",
    "    tokens_wo_sw = [x for x in tokens if x not in stop_words and len(x) > 3]\n",
    "    tokens_stemmed = [stemmer.stem(x) for x in tokens_wo_sw]\n",
    "    return tokens_stemmed\n",
    "\n",
    "def save_sparse_csr(filename,array):\n",
    "    np.savez(filename,data = array.data ,indices=array.indices,\n",
    "             indptr =array.indptr, shape=array.shape )\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return csr_matrix((  loader['data'], loader['indices'], loader['indptr']),\n",
    "                         shape = loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14454, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"input/train.tsv\", sep='\\t')\n",
    "test = pd.read_csv(\"input/test.tsv\", sep='\\t')\n",
    "msk = np.random.rand(len(data)) < 0.01\n",
    "sample_data = data[msk]\n",
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14454, 8)\n",
      "(693359, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thaunayf\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\thaunayf\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\thaunayf\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train = clean_missing(train)\n",
    "test = clean_missing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thaunayf\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py36\\lib\\site-packages\\pandas\\core\\indexing.py:337: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\thaunayf\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py36\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "train = transform_category_name(train)\n",
    "test = transform_category_name(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.log1p(train['price'].as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(train[['item_condition_id', 'shipping']]).as_matrix()\n",
    "X_test =pd.get_dummies(test[['item_condition_id', 'shipping']]).as_matrix()\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=stem_tokenize, decode_error='ignore', strip_accents='unicode', max_df=0.8, min_df=0.001)\n",
    "tfidf_vectorizer.fit(train[\"category_name\"])\n",
    "X_train_cn = tfidf_vectorizer.transform(train[\"category_name\"])\n",
    "X_test_cn = tfidf_vectorizer.transform(test[\"category_name\"])\n",
    "\n",
    "X_train = np.concatenate((X_train, X_train_cn.toarray()), axis=1)\n",
    "X_test = np.concatenate((X_test, X_test_cn.toarray()), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=stem_tokenize, decode_error='ignore', strip_accents='unicode', max_df=0.8, min_df=0.001)\n",
    "tfidf_vectorizer.fit(train[\"brand_name\"])\n",
    "X_train_bn = tfidf_vectorizer.transform(train[\"brand_name\"])\n",
    "X_test_bn = tfidf_vectorizer.transform(test[\"brand_name\"])\n",
    "    \n",
    "X_train = np.concatenate((X_train, X_train_bn.toarray()), axis=1)\n",
    "X_test = np.concatenate((X_test, X_test_bn.toarray()), axis=1)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=stem_tokenize, decode_error='ignore', strip_accents='unicode', max_df=0.8, min_df=0.001)\n",
    "tfidf_vectorizer.fit(train[\"item_description\"])\n",
    "X_train_id = tfidf_vectorizer.transform(train[\"item_description\"])\n",
    "X_test_id = tfidf_vectorizer.transform(test[\"item_description\"])\n",
    "\n",
    "X_train = np.concatenate((X_train, X_train_id.toarray()), axis=1)\n",
    "X_test = np.concatenate((X_test, X_test_id.toarray()), axis=1)\n",
    "\n",
    "    \n",
    "regr = Ridge(alpha=1.0)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(test[[\"test_id\"]])\n",
    "submission['price'] = np.expm1(y_pred)\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
